# Microprofile server properties
server.port=8080


dev.langchain4j.plugin.chat-model.class=dev.langchain4j.model.azure.AzureOpenAiChatModel
dev.langchain4j.plugin.chat-model.config.api-key=${azure.openai.api.key}
dev.langchain4j.plugin.chat-model.config.endpoint=${azure.openai.endpoint}
dev.langchain4j.plugin.chat-model.config.service-version=2024-02-15-preview
dev.langchain4j.plugin.chat-model.config.deployment-name=${azure.openai.deployment.name}
dev.langchain4j.plugin.chat-model.config.temperature=0.1
dev.langchain4j.plugin.chat-model.config.topP=0.1
dev.langchain4j.plugin.chat-model.config.timeout=120s
dev.langchain4j.plugin.chat-model.config.max-retries=2
dev.langchain4j.plugin.chat-model.config.logRequestsAndResponsess=false



smallrye.llm.embedding.store.in-memory.file=embedding.json

# Chat memory configuration, used by ChatAiFactory
chat.memory.max.messages=20

# Fraud detection configuration, used by FraudAiFactory
fraud.memory.max.messages=20

# Location of documents to RAG
app.docs-for-rag.dir=docs-for-rag



